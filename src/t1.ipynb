{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1. Standardize MT5 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: Daily_201708100000_202503140000.csv\n",
      "Processed and saved: H1_201708100000_202503142200.csv\n",
      "Processed and saved: H4_201708100000_202503142000.csv\n",
      "Processed and saved: M15_202012161445_202503131615.csv\n",
      "Processed and saved: M2_202408190410_202503142258.csv\n",
      "Processed and saved: M5_202310121825_202503142255.csv\n"
     ]
    }
   ],
   "source": [
    "def fix_data(folder_path, fixed_path):\n",
    "    # Define the standard column names after dropping <VOL> and renaming <TICKVOL>\n",
    "    standard_columns = ['Datetime', 'Open', 'High', 'Low', 'Close', 'Vol', 'Spread']\n",
    "    \n",
    "    # Create the fixed folder if it doesn't exist\n",
    "    if not os.path.exists(fixed_path):\n",
    "        os.makedirs(fixed_path)\n",
    "    \n",
    "    # Loop through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            fixed_file_path = os.path.join(fixed_path, filename)\n",
    "            \n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path, sep='\\t')  # Assuming tab-separated values\n",
    "            \n",
    "            # Drop the <VOL> column\n",
    "            df.drop(columns=['<VOL>'], inplace=True)\n",
    "            \n",
    "            # Rename <TICKVOL> to 'Vol'\n",
    "            df.rename(columns={'<TICKVOL>': 'Vol'}, inplace=True)\n",
    "            \n",
    "            # Check if the <TIME> column exists\n",
    "            if '<TIME>' in df.columns:\n",
    "                # Combine <DATE> and <TIME> into a single 'Datetime' column\n",
    "                df['Datetime'] = pd.to_datetime(df['<DATE>'] + ' ' + df['<TIME>'], format='%Y.%m.%d %H:%M:%S')\n",
    "                # Drop the original <DATE> and <TIME> columns\n",
    "                df.drop(columns=['<DATE>', '<TIME>'], inplace=True)\n",
    "            else:\n",
    "                # If no <TIME> column, just convert <DATE> to datetime\n",
    "                df['Datetime'] = pd.to_datetime(df['<DATE>'], format='%Y.%m.%d')\n",
    "                # Drop the original <DATE> column\n",
    "                df.drop(columns=['<DATE>'], inplace=True)\n",
    "            \n",
    "            # Reorder columns to ensure 'Datetime' is the first column\n",
    "            df = df[['Datetime'] + [col for col in df.columns if col != 'Datetime']]\n",
    "            df['Datetime'].to_date\n",
    "            \n",
    "            # Rename other columns to standard names\n",
    "            df.columns = standard_columns\n",
    "            \n",
    "            # Save the corrected DataFrame to the fixed folder\n",
    "            df.to_csv(fixed_file_path, index=False)\n",
    "            \n",
    "            print(f\"Processed and saved: {filename}\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = '../data/mt5'\n",
    "fixed_path = '../data/gold'\n",
    "fix_data(folder_path, fixed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2. Add Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Datetime     Open     High      Low    Close    Vol  Spread  \\\n",
      "44864 2025-03-14 13:00:00  2993.40  2999.19  2993.28  2993.43   7649      10   \n",
      "44865 2025-03-14 14:00:00  2993.42  2999.64  2993.29  2993.87   8761      10   \n",
      "44866 2025-03-14 15:00:00  2993.85  2996.13  2983.46  2985.73  11013      10   \n",
      "44867 2025-03-14 16:00:00  2985.73  2993.40  2982.06  2985.42  10756      10   \n",
      "44868 2025-03-14 17:00:00  2985.40  2986.46  2978.50  2984.54   8762      10   \n",
      "44869 2025-03-14 18:00:00  2984.55  2990.07  2982.92  2989.79   6906      11   \n",
      "44870 2025-03-14 19:00:00  2989.81  2990.35  2986.44  2986.60   5383      11   \n",
      "44871 2025-03-14 20:00:00  2986.67  2987.06  2983.14  2983.35   4636      11   \n",
      "44872 2025-03-14 21:00:00  2983.36  2986.03  2982.12  2984.01   4735      11   \n",
      "44873 2025-03-14 22:00:00  2984.02  2988.43  2981.75  2984.24   2029      11   \n",
      "\n",
      "       DayOfWeek       ATR       EMA_20       EMA_50      EMA_100      EMA_200  \n",
      "44864          4  7.377143  2982.896097  2962.081912  2943.183966  2927.597842  \n",
      "44865          4  7.342143  2983.941231  2963.328504  2944.187650  2928.257267  \n",
      "44866          4  7.964286  2984.111590  2964.206994  2945.010270  2928.829135  \n",
      "44867          4  8.487857  2984.236200  2965.038877  2945.810463  2929.392228  \n",
      "44868          4  8.450000  2984.265133  2965.803627  2946.577385  2929.940962  \n",
      "44869          4  8.642143  2984.791311  2966.744269  2947.433080  2930.536475  \n",
      "44870          4  8.275000  2984.963567  2967.522925  2948.208662  2931.094321  \n",
      "44871          4  7.867143  2984.809894  2968.143595  2948.904531  2931.614278  \n",
      "44872          4  7.787857  2984.733714  2968.765807  2949.599688  2932.135628  \n",
      "44873          4  7.805714  2984.686693  2969.372638  2950.285635  2932.654080  \n"
     ]
    }
   ],
   "source": [
    "def calculate_atr(df, period=14):\n",
    "    \"\"\"Calculate the Average True Range (ATR) for a given DataFrame.\"\"\"\n",
    "    high_low = df['High'] - df['Low']\n",
    "    high_close = abs(df['High'] - df['Close'].shift())\n",
    "    low_close = abs(df['Low'] - df['Close'].shift())\n",
    "    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    atr = true_range.rolling(window=period).mean()\n",
    "    return atr\n",
    "\n",
    "def add_features(df):\n",
    "    \"\"\"Add features like day of the week, ATR, and EMAs to the DataFrame.\"\"\"\n",
    "    # Add day of the week (0 = Monday, 6 = Sunday)\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "    df['DayOfWeek'] = df['Datetime'].dt.dayofweek\n",
    "    \n",
    "    # Calculate ATR (Average True Range)\n",
    "    df['ATR'] = calculate_atr(df)\n",
    "    \n",
    "    # Calculate EMAs (Exponential Moving Averages)\n",
    "    df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "    df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n",
    "    df['EMA_100'] = df['Close'].ewm(span=100, adjust=False).mean()\n",
    "    df['EMA_200'] = df['Close'].ewm(span=200, adjust=False).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('..\\\\data\\\\gold\\\\H1_201708100000_202503142200.csv')\n",
    "features = add_features(df)\n",
    "print(features.tail(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
